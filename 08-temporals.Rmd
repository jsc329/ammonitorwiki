---
title: "Chapter 8: The Temporals Table"
output:
  github_document:
    toc: true
    toc_depth: 3
    df_print: tibble
bibliography: refs.bib
csl: plos.csl
---

```{r, echo = F}
# to create md file for the code.usgs.gov wiki, in the console type:
# rmarkdown::render(input = "08-temporals.Rmd", output_format = "md_document", output_file = "Chapter 8 - The Temporals Table.md")

```

```{r echo = F}
# Set up chapter table and figure counters; figure folder
source("includes.R")
options(table_counter_str = "<b>Table 8.%s</b> ")
options(fig_caption_no_sprintf = "<b>Figure 8.%s</b>")
knitr::opts_chunk$set(fig.path = 'Chap8_Figs/')
```

```{r, echo = FALSE, message = FALSE, results = 'hide'}
# Clean up for re-knits:
db.name <- 'Chap8.sqlite'
db.path <- paste0(getwd(), '/database/', db.name)
if (file.exists('db.path')) dbDisconnect(conn = RSQLite::SQLite(), dbname = db.path) 
file.remove(db.path) 
```

The **temporals** table tracks temporal information -- such as weather conditions and sunrise times -- at monitoring locations. Temporal information can be used as covariates in an analysis. For example, species distribution patterns may be limited by a range of temperatures, species behavioral patterns may be affected by moon phase, and species detection (e.g., vocalization) may be a function of weather conditions. Additionally, temporal information can be leveraged to automatically set the recording or photo **schedule** (Chapter 9: Schedule) and to automatically update the **prioritization** table (Chapter 10). Thus, this chapter and the two that follow differ from previous chapters in that the **temporals**, **schedule**, and **prioritization** tables are all updated automatically. Instead of using SQLite syntax or an MS Access interface, you will use **AMMonitor** functions to directly populate these tables in R. 

In this chapter, we will use the `dbCreateSample()` function to create a database called "Chap8.sqlite", which will be stored in a folder (directory) called "database" within the **AMMonitor** main directory (which should be your working directory in R). Recall that `dbCreateSample()` generates all tables of an **AMMonitor** database, and then pre-populates sample data into tables specified by the user. For demonstration purposes, we will only pre-populate a few necessary tables below, though the **temporals** table will start out empty. 

```{r}
# Create a sample database for this chapter
dbCreateSample(db.name = "Chap8.sqlite", 
               file.path = paste0(getwd(),"/database"), 
               tables =  c('people', 'locations',
                           'deployment', 'equipment',
                           'accounts'))
```

We begin by connecting to the database. First, we initialize a character object, **db.path**, that holds the database's full file path. Then, we create a database connection object, **conx**, using RSQLite's `dbConnect()` function, where we identify the SQLite driver in the ‘drv’ argument, and our **db.path** object in the ‘dbname’ argument:

```{r}
# Establish the database file path as db.path
db.path <- paste0(getwd(), '/database/Chap8.sqlite')

# Connect to the database
conx <- RSQLite::dbConnect(drv = dbDriver('SQLite'), dbname = db.path)
```

As always, we send a SQL statement that will enforce foreign key constraints. 
```{r}
# Turn the SQLite foreign constraints on
RSQLite::dbSendQuery(conn = conx, statement = 
              "PRAGMA foreign_keys = ON;"
          )
```

Finally, to keep the demonstrations in this chapter concise, we will assume that only three of our 50 example monitoring locations are actively being monitored. That is, we will assume that the equipment deployed at 47 locations has been retrieved. We will deactivate deployments at monitoring locations 'location\@4' through 'location\@50' by sending an UPDATE query to `dbExecute()`, wherein we assign an arbitrary date to the *dateRetrieved* column of the deployment table to indicate that these locations are not actively monitored:

```{r}
RSQLite::dbExecute(conn = conx, statement =  "UPDATE deployment 
                        SET dateRetrieved = '2016-01-20'
                        WHERE locationID NOT IN 
                        ('location@1', 'location@2', 'location@3')")
```
This action returns a '47' to indicate that 47 records have applied the action of setting *dateRetrieved* equal to '2016-01-20'. Next, we will gather temporal data for the three active stations that remain.

# The Temporals Table

The **temporals** table tracks temporal data at monitoring locations. **AMMonitor** collects weather data via the [Dark Sky API](https://darksky.net/forecast/40.7127,-74.0059/us12/en); thus the data tracked in the **temporals** table roughly matches data returned from Dark Sky. We will cover the Dark Sky API later in this chapter.

We begin with a look at the **temporals** table summary information using `dbTables()`:
```{r}
# Look at information about the temporals table
dbTables(db.path = db.path, table = "temporals")
```
Notice that the **temporals** table contains 25 fields (columns) that are a mix of mostly VARCHAR and REAL number data types. The *locationID* specifies the monitoring location. 

The *locationID*, *type*, *date* and *time* serve as primary keys (a composite primary key), and all four are required values (*notnull* = 1). The *locationID* field maps to the *locationID* field in the **locations** table, which serves as a foreign key, as confirmed with the following code:

```{r, eval = T}
# Return foreign key information for the deployment table
RSQLite::dbGetQuery(conn = conx, statement = "PRAGMA foreign_key_list(temporals);")

```

Here, one can see that the *locationID* field in table **locations** maps to the *locationID* field in table **temporals**. 

The **temporals** table can store both forecast data and historical (observed) weather data. Thus, the *type* column will either contain the word "forecast" or "historical". The column *type* is included in the primary key in the event that both forecast *and* historical data are gathered for a given *locationID*, *date*, and *time*.

All other fields, such as *sunriseTime*, *temperature*, *humidity*, and *moonPhase*, are not technically required. Depending on the weather forecast and/or historical data available, certain locations, dates, and times may not contain data for certain columns. For example, if there is no precipitation during a given hour, the *precipType* column will contain NAs.

We can use `dbGetQuery()` to send a query that will return the number of records present in our **temporals** table in the sample **AMMonitor** database:

```{r}
RSQLite::dbGetQuery(conn = conx, statement = "SELECT COUNT(*) FROM temporals;")
```

As shown, there are no records in this table. We do not interact with the **temporals** table the way we have with previously introduced tables. Instead, we use the **AMMonitor** function `temporalsGet()` to acquire data and auto-populate this table.

# The Dark Sky API

The function `temporalsGet()` uses the [Dark Sky API](https://darksky.net/) to collect weather data. Read more about Dark Sky's data sources [here](https://darksky.net/dev/docs/sources). `temporalsGet()` allows users to obtain weather information around the world (where available) either as 24-hour forecasts or as hourly historical observation data. Dark Sky draws from several weather data sources, aggregating them to provide forecasts for selected locations. Their data sources include the USA NCEP’s Canadian Meteorological Center ensemble model ('cmc'), the Environment and Climate Change Canada's Public Alert System ('ecpa'), U.S. NOAA's Global Forecast System ('gfs'), U.S. NOAA's High-Resolution Rapid Refresh Model ('hrrr'), the German Meteorological Office's icosahedral nonhydrostatic ('icon'), U.S. NOAA's Integrated Surface Database ('isd'), U.S. NOAA/ESRL's Meteorological Assimilation Data Ingest System ('madis'), U.S. NOAA's North American Mesoscale Model ('nam'), U.S. NOAA's Public Alert System ('nwspa'), and U.S. NOAA/NCEP's Short-Range Ensemble Forecast ('sref'), in addition to several non-North American [weather data and weather forecast sources](https://darksky.net/dev/docs/sources). Not all data sources will be available for all points on the globe. 

To use `temporalsGet()` for your project, you first need to set up a Dark Sky account as a developer by visiting their [API Development Page (https://darksky.net/dev/docs)](https://darksky.net/dev/docs) and clicking the Sign Up button in the upper righthand corner:

```{r, eval = F}
# Browse to the Dark Sky Development Page
browseURL("https://darksky.net/dev/docs")
```

<kbd>

```{r, out.width = '100%', echo = F}

knitr::include_graphics('Chap8_Figs/darksky-signup.png', dpi = 500)
```

</kbd>

>*Figure 8.1. You will need to acquire a Dark Sky API in order to automatically populate the temporals table.*


After providing an email address and a password, you will receive a Dark Sky key, which is a character string along the lines of 'd8db31f709f973f61x4d29afe0b67e93' (merely an example; it is not a real key). You should store this string in the **settings folder** as an RDS file with a name of your choice.

<kbd>

```{r, out.width = '100%', echo = F}

knitr::include_graphics('Chap8_Figs/directories.PNG', dpi = 500)
```

</kbd>

>*Figure 8.2. The "settings" directory is a reasonable place to store all AMMonitor keys.*


The code below provides an example of how to save this key as an RDS file, assuming that your working directory is the main **AMMonitor** directory, with a folder called **settings** as a sub-directory:

```{r, eval = FALSE}
saveRDS(object = 'd8db31f709f973f61x4d29afe0b67e93', 
        file = 'settings/dark-sky-key.RDS')
```

The first 1000 API calls you make per day are free. In effect, if you are gathering forecasts for fewer than 1000 monitoring sites per day, you will pay nothing. If you wish to gather large amounts of historical data in one day, you will pay a fee.

# Gathering forecast data for tomorrow

The first way to use `temporalsGet()` is to acquire 24-hour forecast data for tomorrow, which we demonstrate below. The function will output 24 records (one for each hour) for each actively monitored location (as specified in the **deployment** table). 

The `temporalsGet()` function has six arguments. First, as usual, we point to our database by putting the **db.path** object in the 'db.path' argument. Second, we put the file path to our stored RDS Dark Sky key into the 'temporals.key' argument. Third, we indicate the type of data we want in the 'type' argument. The options are "forecast" (default), or "historical", and below we select "forecast". Fourth, we set the 'dates' argument to NULL, which is the default action when gathering forecast data. Fifth, the 'locationID' argument allows us to specify individual locationIDs for which we want to gather temporal data. If 'locationID' is left as the default NULL, the function automatically gathers weather data for all locationIDs actively monitored according to the **deployment** table. Alternatively, a user can pass in a vector of specific locationIDs, or indicate "all" to retrieve weather information for all locations, regardless of whether they are actively being monitored. Lastly, we have an argument called 'db.insert'. Often, we may wish to test a function before adding data to the database, and in `temporalsGet()`, we accomplish this by setting the 'db.insert' argument to FALSE. This action returns a list object for us to inspect, but ensures that no new data are automatically added to the **temporals** table:

```{r}
# Gather forecast data, set db.insert to FALSE
# Leave dates = NULL to get 24-hr forecast for tomorrow
test_temporals <- temporalsGet(db.path = db.path,
                               temporals.key = 'settings/dark-sky-key.RDS',
                               type = 'forecast', 
                               dates = NULL,
                               locationID = NULL,
                               db.insert = FALSE)
```


The function generates progress messages telling us that it is gathering forecast data for all three monitoring locations in the sample database. 

When finished, `temporalsGet()` returns a list object containing two items: 1) a data.table of temporal data, and 2) a list of data sources used for each call to the API.

```{r}
# View the top level structure of the returned results
str(test_temporals, max.level = 1)
```

Below, we view the data sources Dark Sky used to generate the forecast, using the '$' sign to access this list. Here, we look at the structure of the list only.

```{r}
# View the structure of data sources list
str(test_temporals$data.sources)
```

The **test_temporals$data.sources** object is a list of three because there is data source information about all three locations. Each set of location-specific source data contains four elements. The **sources** element provides codes for each of the data sources Dark Sky used to generate the aggregated forecast. For example, the code 'gfs' stands for NOAA's [Global Forecast System](https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs), and 'hrrr' stands for NOAA's [High Resolution Rapid Refresh](https://rapidrefresh.noaa.gov/hrrr/) model. [All Dark Sky data source codes are available here](https://darksky.net/dev/docs/sources). The **date** element tells us the date for which certain sources were used. The **nearest.station** object gives the distance, in **units**, to the nearest weather station used. Because the units returned here are "us", the distance to the nearest station is given in miles. 

Secondly, we can view the temporal data itself, also by using list indexing notation ($):
```{r}
# View the data, rows 1:10 and columns 1:5 
test_temporals$temporal.data[1:10, 1:5]
```

With three active monitoring stations, this example returns 3 locations * 24 hours = 72 records and 25 columns, confirmed with `dim()`. 
```{r}
# Get the dimensions of the returned data.table
dim(test_temporals$temporal.data)
```

The first 10 records of the **test_temporals$temporal.data** object show hourly data for location\@1 starting at 12AM (or 00:00:00). The *type* column indicates forecast data, while the *date* and *time* columns track date and time. The *hour* column logs the hour of the day. 

Many columns of temporal data are returned by this function. Below, we view columns 7:12:
```{r}
# View the data, rows 1:10 and columns 7:12
test_temporals$temporal.data[1:10, 7:12]
```

Sun activity is logged in the *sunriseTime* and *sunsetTime* columns. If *precipIntensity* and *precipProbability* are 0, then *precipType* will have an NA value (read more about Dark Sky's precipitation probabilities [here](https://darksky.net/dev/docs/faq#faq-data-availability-and-accuracy)). Remaining columns track the *temperature* (in degrees Fahrenheit), *dewPoint* (in degrees Fahrenheit), *humidity* (in relative humidity; value between 0 and 1 inclusive), *pressure* (sea level air pressure in millibars), *windSpeed* (in miles per hour), *windGust* (in miles per hour), *windBearing* (wind origin direction in degrees, with true north at 0 degrees and progressing clockwise), *cloudCover* (the percentage of sky covered by clouds; value between 0 and 1 inclusive), *uvIndex*, *visibility* (average visibility in miles, capped at 10 miles), *ozone* (columnar density of total atmospheric ozone at the given time in Dobson units), and *moonPhase* ("fractional part of the lunation number during the given day: a value of 0 corresponds to a new moon, 0.25 to a first quarter moon, 0.5 to a full moon, and 0.75 to a last quarter moon. Ranges in between these represent waxing crescent, waxing gibbous, waning gibbous, and waning crescent moons, respectively"). The *nearestStation* column tracks the distance to the nearest weather station identified by Dark Sky, and the *units* give the distance units to the nearest weather station (units of 'us' indicate that the distance is given in miles). Lastly, the *timestamp* column tracks the system time on your computer at which the data were acquired. 

Once we have tested the function and are satisfied that we understand how it works, we can add the data to the database by re-running the function with 'db.insert' set to TRUE. (Note that the content of the **\$data.sources** object is not added to the database.)

```{r, eval = TRUE, message = FALSE}

# Gather forecast data and add it to the database
temporals <- temporalsGet(db.path = db.path,
                          temporals.key = 'settings/dark-sky-key.RDS',
                          type = 'forecast',
                          dates = NULL,
                          locationID = NULL,
                          db.insert = TRUE)
```


Alternatively, if we were satisfied with the test output and saved it as an object, we could simply append the **\$temporal.data** list object to the **temporals** table using `dbWriteTable()` instead of rerunning the function.

We can verify that our data have been added to the database by using `dbGetQuery()`, returning only a handful of columns and invoking the term 'LIMIT 10' in our SQL statement to limit the returned table to the first ten records: 

```{r, eval = TRUE}
# Confirm that the data has been added to the database,
# Viewing a few selected columns and the first 10 records:
RSQLite::dbGetQuery(conx, "SELECT locationID, type, date, 
                                  time, dewpoint, pressure, moonPhase 
                          FROM temporals LIMIT 10") 
```


# Gathering historical data

The second way to use `temporalsGet()` is to gather historical data. This time, instead of setting the 'dates' argument to NULL, we input a few dates over which we want to gather data for our three sample database locations. We can add a character vector containing as many dates as we want to this argument, but all dates must be in the format YYYY-mm-dd. We are mindful that **the number of dates in the vector** times **the number of active monitoring locations in the deployment table** will give us the number of API calls `temporalsGet()` makes to the Dark Sky API. In this case, two dates times three active monitoring locations equals a total of six calls to the API.

```{r, eval = TRUE, message = FALSE}

# Gather historical data, but don't add it to the database

# Set db.insert to FALSE to return the data without adding it to the database
test_temporals <- temporalsGet(db.path = db.path,
                               temporals.key = './settings/dark-sky-key.RDS',
                               type = 'historical',
                               dates = c('2016-04-01', '2016-04-02'),
                               locationID = NULL,
                               db.insert = FALSE)

# View a subset of the temporal data (rows 1:10, columns 1:6): 
test_temporals$temporal.data[1:10, 1:6]
```

The function again generates progress messages (not displayed here) informing us it is gathering forecast data for all six location-dates. Most of the columns are the same as for the forecast data, except that the *type* column now indicates we that we have gathered historical data. Some columns may contain NAs if no historical data are available for that time period and location.

As before, once we have tested the function and are satisfied with the results, we can add the data to the database either by binding it in manually with `dbWriteTable()`, or by re-running the function with the 'db.insert' argument set to TRUE. 

```{r, eval = TRUE, message = FALSE}
# If satisfied with testing, can set test = FALSE to run the function
# and add historical (observed) data directly to the database
temporals <- temporalsGet(db.path = db.path,
                          temporals.key = './settings/dark-sky-key.RDS',
                          type = 'historical',
                          dates = c('2016-04-01', '2016-04-02'),
                          locationID = NULL,
                          db.insert = TRUE)
```


# Querying the temporals table

Briefly, the **AMMonitor** function `qryTemporals()` is a simple convenience function that returns all data from the most recent date available in the **temporals** table. This function is used internally within functions covered in subsequent chapters, but may also be helpful for users who have already initialized a **conx** object connected to the database, and who wish to avoid constructing a SQLite query to view the most recent available **temporals** data.

```{r}
# Query the temporals table
latest_temporals <- qryTemporals(conn = conx)

# Look at the first ten records of the latest_temporals object
latest_temporals[1:10,1:6]

```

In future chapters, the **temporals** data plays a role in optimizing the recordings and photo schedules, and can also be used in downstream analyses. 

When finished, we disconnect from the database with the `dbDisconnect()` function.

```{r}
# Disconnect from the database
RSQLite::dbDisconnect(conx)

```

# Running temporalsGet() in a script

While the `temporalsGet()` function can be used to gather historical temporal data associated with monitoring sites, it may be employed on a daily basis to retrieve predicted temporal information (i.e., weather data for the next 24 hours). To ease the process of manually running this function each day, a monitoring team may automatically retrieve temporal data via a "script" sourced each morning. Scripts are described in detail in Chapter 19: Scripts. 


# The Temporals Table in Access


The temporals form in the Microsoft Access front end can be accessed as a secondary tab under the Locations tab. This is the first look at a "Hands Off!" form in Access. The **temporals** table is entirely populated by the `temporalsGet()` function, so it should not be edited by hand. 

<kbd>

```{r, out.width = '100%', echo = F, fig.align = 'center'}

knitr::include_graphics('Chap8_Figs/temporals.PNG', dpi = 500)
```

</kbd>

>*Figure 8.3. The temporals table is displayed in form view here.  It is located under the primary tab, Locations.*


# Chapter Summary

In this chapter, we reviewed how to use the **AMMonitor** `temporalsGet()` function to gather temporal and weather data for active study locations in a monitoring program. `temporalsGet()` operates via the Dark Sky API, and offers options for acquiring either forecast or historical data. This function also offers a 'db.insert' argument that allows users to test the function before adding data directly to the database's **temporals** table.  Temporal data will be used in future chapters, starting with Chapter 9.  
